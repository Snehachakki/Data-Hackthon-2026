Government Data Analytics Project


Data Cleaning
The dataset was sourced from official government open data platforms. Initial inspection was performed to understand the data structure, column types, and overall data quality. Missing values were identified and handled appropriately, duplicate records were removed, and inconsistent entries were corrected. Data types were standardized, and columns were renamed for clarity and consistency. These preprocessing steps ensured the dataset was clean, reliable, and suitable for analysis.

Data Visualization
After data cleaning, Power BI was used to build interactive dashboards. Visuals such as bar charts, column charts, stacked charts, tables, and slicers were created to compare key metrics across regions and categories. The dashboards support dynamic filtering and clear data storytelling, enabling easy identification of trends, patterns, and insights from the government dataset.

Machine Learning
Machine learning models were implemented to analyze patterns and relationships within the cleaned dataset. Decision Tree was used for its interpretability and ability to explain feature-based decisions, while Random Forest was applied to improve accuracy and reduce overfitting by combining multiple decision trees. Feature engineering and train-test splitting were performed before model training. Model performance was evaluated using standard metrics to ensure reliability and consistency of results.

Tools Used

Python (Pandas, NumPy, Scikit-learn)
Machine Learning (Decision Tree, Random Forest)
Power BI
Government Open Data Sources
